# Sign Language Detection Using LSTM-RNN 🤟📷

This project detects basic English alphabet gestures from sign language using an LSTM-RNN deep learning model. It captures real-time gestures via webcam and translates them into corresponding text. <br>
Designed to support communication for the hearing-impaired through AI.

<br>

## 📌 Project Highlights

- Real-time sign language detection using webcam<br>
- Recognizes selected basic English alphabets<br>
- Uses TensorFlow-based LSTM-RNN architecture<br>
- Structured dataset with bounding box annotations<br>
- Modular design for easy updates and improvements<br>

<br>

## 🗂️ Project Structure

Sign_Language_Detection/
├── data/
│ ├── train/
│ ├── test/
│ └── validation/
│ └── *.csv (annotations)
├── collection_data/
├── traindata/
├── function.py
├── app.py
└── README.md
<br>

<br>

## ⚙️ Technologies Used

- Python<br>
- TensorFlow<br>
- OpenCV<br>
- LSTM-RNN<br>
- NumPy, Pandas<br>

<br>

## 🚀 How to Run

1. Clone the repository:<br>
   `git clone https://github.com/your-username/Sign_Language_Detection_Using_LSTM-RNN-.git` <br>
   `cd Sign_Language_Detection_Using_LSTM-RNN-` <br><br>

2. Install dependencies:<br>
   `pip install -r requirements.txt` <br><br>

3. Run the app:<br>
   `python app.py` <br><br>

4. Webcam will open and display detected alphabets in real-time.

<br>

## 📈 Future Scope

- Add full ASL gesture recognition<br>
- Integrate text-to-speech for alphabet pronunciation<br>
- Develop interactive web UI using JavaScript<br>

<br>

## 🙋‍♀️ About

This is a **college minor project** focusing on bridging communication gaps using AI-powered sign detection.


