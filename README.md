# Sign Language Detection Using LSTM-RNN ğŸ¤ŸğŸ“·

This project detects basic English alphabet gestures from sign language using an LSTM-RNN deep learning model. It captures real-time gestures via webcam and translates them into corresponding text. <br>
Designed to support communication for the hearing-impaired through AI.

<br>

## ğŸ“Œ Project Highlights

- Real-time sign language detection using webcam<br>
- Recognizes selected basic English alphabets<br>
- Uses TensorFlow-based LSTM-RNN architecture<br>
- Structured dataset with bounding box annotations<br>
- Modular design for easy updates and improvements<br>

<br>

## ğŸ—‚ï¸ Project Structure

Sign_Language_Detection/
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ train/
â”‚ â”œâ”€â”€ test/
â”‚ â””â”€â”€ validation/
â”‚ â””â”€â”€ *.csv (annotations)
â”œâ”€â”€ collection_data/
â”œâ”€â”€ traindata/
â”œâ”€â”€ function.py
â”œâ”€â”€ app.py
â””â”€â”€ README.md
<br>

<br>

## âš™ï¸ Technologies Used

- Python<br>
- TensorFlow<br>
- OpenCV<br>
- LSTM-RNN<br>
- NumPy, Pandas<br>

<br>

## ğŸš€ How to Run

1. Clone the repository:<br>
   `git clone https://github.com/your-username/Sign_Language_Detection_Using_LSTM-RNN-.git` <br>
   `cd Sign_Language_Detection_Using_LSTM-RNN-` <br><br>

2. Install dependencies:<br>
   `pip install -r requirements.txt` <br><br>

3. Run the app:<br>
   `python app.py` <br><br>

4. Webcam will open and display detected alphabets in real-time.

<br>

## ğŸ“ˆ Future Scope

- Add full ASL gesture recognition<br>
- Integrate text-to-speech for alphabet pronunciation<br>
- Develop interactive web UI using JavaScript<br>

<br>

## ğŸ™‹â€â™€ï¸ About

This is a **college minor project** focusing on bridging communication gaps using AI-powered sign detection.


